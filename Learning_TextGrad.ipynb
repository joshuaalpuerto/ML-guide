{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshuaalpuerto/ML-guide/blob/main/Learning_TextGrad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "36a9c615-17a0-455c-8f9c-f0d25fb8824b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-11T15:43:10.594204491Z",
          "start_time": "2024-06-11T15:43:10.589328053Z"
        },
        "id": "36a9c615-17a0-455c-8f9c-f0d25fb8824b",
        "outputId": "823516c7-4f81-4ed3-cf94-bf423ed3eca4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for textgrad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU textgrad --progress-bar off\n",
        "!pip install -qU openai --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title load fireworks API key\n",
        "#connect to google drive\n",
        "from google.colab import drive\n",
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('/content/drive/MyDrive/env/env.json') as jsonfile:\n",
        "    env = json.load(jsonfile)\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = env['fireworks.ai']['apiKey']\n",
        "os.environ['OPENAI_BASE_URL'] = \"https://api.fireworks.ai/inference/v1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_loXjG44xfJ",
        "outputId": "d002238f-a83c-4323-99af-8228c2ae7a45"
      },
      "id": "k_loXjG44xfJ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "from textgrad.engine import get_engine\n",
        "from textgrad import Variable\n",
        "from textgrad.optimizer import TextualGradientDescent\n",
        "from textgrad.loss import TextLoss\n",
        "from textgrad.engine.openai import ChatOpenAI\n",
        "\n",
        "engine = ChatOpenAI(model_string='accounts/fireworks/models/mixtral-8x7b-instruct')\n",
        "eval_engine = ChatOpenAI(model_string='accounts/fireworks/models/mixtral-8x22b-instruct')"
      ],
      "metadata": {
        "id": "imcaXNen5ats"
      },
      "id": "imcaXNen5ats",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c65fb4456d84c8fc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-11T15:43:17.669096228Z",
          "start_time": "2024-06-11T15:43:17.665325560Z"
        },
        "id": "c65fb4456d84c8fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "98255c30-1bd1-4664-ff66-ade3a8bf121d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello! I'm an artificial intelligence, so I don't have feelings, but I'm here and ready to assist you. How can I help you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "x = Variable(\"A sntence with a typo\", role_description=\"The input sentence\", requires_grad=True)\n",
        "engine.generate(\"Hello how are you?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b627edc07c0d3737",
      "metadata": {
        "collapsed": false,
        "id": "b627edc07c0d3737"
      },
      "source": [
        "## Introduction: Loss\n",
        "\n",
        "Again, Loss in TextGrad is the metaphorical equivalent of loss in PyTorch. We use Losses in different form in TextGrad but for now we will focus on a simple TextLoss. TextLoss is going to evaluate the loss wrt a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "252e0a0152b81f14",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-11T15:44:32.894722136Z",
          "start_time": "2024-06-11T15:44:32.890708561Z"
        },
        "id": "252e0a0152b81f14"
      },
      "outputs": [],
      "source": [
        "system_prompt = Variable(\"Evaluate the correctness of this sentence\", role_description=\"The system prompt\")\n",
        "loss = TextLoss(system_prompt, engine=engine)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff137c99e0659dcc",
      "metadata": {
        "collapsed": false,
        "id": "ff137c99e0659dcc"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6f05ec2bf907b3ba",
      "metadata": {
        "collapsed": false,
        "id": "6f05ec2bf907b3ba"
      },
      "source": [
        "## Introduction: Optimizer\n",
        "\n",
        "Keeping on the analogy with PyTorch, the optimizer in TextGrad is the object that will update the parameters of the model. In this case, the parameters are the variables that have `requires_grad` set to `True`.\n",
        "\n",
        "**NOTE** This is a text optimizer! It will do all operations with text!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78f93f80b9e3ad36",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-11T15:44:33.741130951Z",
          "start_time": "2024-06-11T15:44:33.734977769Z"
        },
        "id": "78f93f80b9e3ad36"
      },
      "outputs": [],
      "source": [
        "optimizer = TextualGradientDescent(parameters=[x], engine=engine)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d26883eb74ce0d01",
      "metadata": {
        "collapsed": false,
        "id": "d26883eb74ce0d01"
      },
      "source": [
        "## Putting it all together\n",
        "\n",
        "We can now put all the pieces together. We have a variable, an engine, a loss, and an optimizer. We can now run a single optimization step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9817e0ae0179376d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-11T15:44:41.730132530Z",
          "start_time": "2024-06-11T15:44:34.997777872Z"
        },
        "id": "9817e0ae0179376d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0c7126-5b84-4d23-bf4f-7157f75c93ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:TextualGradientDescent prompt for update\n",
            "INFO:textgrad:TextualGradientDescent optimizer response\n",
            "INFO:textgrad:TextualGradientDescent updated text\n"
          ]
        }
      ],
      "source": [
        "l = loss(x)\n",
        "l.backward(engine)\n",
        "optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77e3fab0efdd579e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-11T15:44:41.738985151Z",
          "start_time": "2024-06-11T15:44:41.731989729Z"
        },
        "id": "77e3fab0efdd579e",
        "outputId": "6abafe38-9030-4c5b-f12c-6f295826553c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A sentence with a typo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "x.value"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solution optimization\n",
        "\n",
        "From this [notebook](https://colab.research.google.com/github/zou-group/TextGrad/blob/main/examples/notebooks/Tutorial-Solution-Optimization.ipynb) the result from our model is not good compared gpt4o."
      ],
      "metadata": {
        "id": "2v3f5XKg-7p4"
      },
      "id": "2v3f5XKg-7p4"
    },
    {
      "cell_type": "code",
      "source": [
        "import textgrad as tg\n",
        "\n",
        "initial_solution = \"\"\"To solve the equation 3x^2 - 7x + 2 = 0, we use the quadratic formula:\n",
        "x = (-b ± √(b^2 - 4ac)) / 2a\n",
        "a = 3, b = -7, c = 2\n",
        "x = (7 ± √((-7)^2 + 4(3)(2))) / 6\n",
        "x = (7 ± √73) / 6\n",
        "The solutions are:\n",
        "x1 = (7 + √73)\n",
        "x2 = (7 - √73)\"\"\"\n",
        "\n",
        "solution = tg.Variable(initial_solution,\n",
        "                       requires_grad=True,\n",
        "                       role_description=\"solution to the math question\")\n",
        "\n",
        "loss_system_prompt = tg.Variable(\"\"\"You will evaluate a solution to a math question.\n",
        "Do not attempt to solve it yourself, do not give a solution, only identify errors. Be super concise.\"\"\",\n",
        "                                 requires_grad=False,\n",
        "                                 role_description=\"system prompt\")\n",
        "\n",
        "loss_fn = tg.TextLoss(loss_system_prompt, engine=engine)\n",
        "optimizer = tg.TGD(parameters=[solution], engine=eval_engine)"
      ],
      "metadata": {
        "id": "vkmGWyGv_FWi"
      },
      "id": "vkmGWyGv_FWi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_fn(solution)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAXPaDlJ_gyh",
        "outputId": "fbefe2cd-199c-4929-996d-d1f072fa902c"
      },
      "id": "VAXPaDlJ_gyh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:textgrad:LLMCall function forward\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Variable(value=The solutions are correct, but the expression for x1 is missing a multiplication sign. It should be:\n",
              "x1 = (7 + √73) / 6\n",
              "Otherwise, the solution is correct and there are no errors to point out., role=response from the language model, grads=)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward(engine=eval_engine)\n",
        "optimizer.step()\n",
        "print(solution.value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "074069iT_9H6",
        "outputId": "00a777b3-d81a-4638-fce7-224db923b301"
      },
      "id": "074069iT_9H6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:TextualGradientDescent prompt for update\n",
            "INFO:textgrad:TextualGradientDescent optimizer response\n",
            "INFO:textgrad:TextualGradientDescent updated text\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To solve the equation 3x^2 - 7x + 2 = 0, we use the quadratic formula:\n",
            "x = (-b ± √(b^2 - 4ac)) / 2a\n",
            "a = 3, b = -7, c = 2\n",
            "x = (7 ± √((-7)^2 + 4(3)(2))) / 6\n",
            "The solutions are:\n",
            "x1 = (7 + √73) / 6\n",
            "x2 = (7 - √73) / 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Another solution optimization example\n",
        "\n",
        "import textgrad as tg\n",
        "\n",
        "\n",
        "model = tg.BlackboxLLM(engine=engine)\n",
        "question_string = (\"If it takes 1 hour to dry 25 shirts under the sun, \"\n",
        "                   \"how long will it take to dry 30 shirts under the sun? \"\n",
        "                   \"Reason step by step\")\n",
        "\n",
        "question = tg.Variable(question_string,\n",
        "                       role_description=\"question to the LLM\",\n",
        "                       requires_grad=False)\n",
        "\n",
        "answer = model(question)\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gko3gsprwqqM",
        "outputId": "fe5079fc-a552-4f48-ab8b-de63e524a1d2"
      },
      "id": "Gko3gsprwqqM",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:textgrad:LLMCall function forward\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Variable(value=Sure, I'd be happy to help you reason through this problem!\n",
              "\n",
              "1. First, let's consider how long it takes to dry one shirt in the sun. From the information given, we know that 25 shirts take 1 hour to dry. So, if we divide the number of shirts by the time it takes to dry them, we can find out how long it takes to dry one shirt. That is, 25 shirts / 1 hour = 1 shirt per hour.\n",
              "\n",
              "2. Now, if we want to dry 30 shirts, and it takes 1 hour to dry 1 shirt, then to find out how long it will take to dry 30 shirts, we simply multiply the number of shirts by the time it takes to dry one shirt. That is, 30 shirts * 1 hour per shirt = 30 hours.\n",
              "\n",
              "However, this answer assumes that you can only dry one shirt at a time, which may not be the case. If you have space to lay out all 30 shirts at once, then the drying time would still be 1 hour, just like it was for 25 shirts. The drying time depends on the rate of drying (which seems to be about 25 shirts per hour in this case), not the total amount of time each shirt needs to dry.\n",
              "\n",
              "So, the answer could be either 30 hours (if you can only dry one shirt at a time) or 1 hour (if you can dry all 30 shirts at once). I would need more information about your drying setup to give a more precise answer., role=response from the language model, grads=)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer.set_role_description(\"concise and accurate answer to the question\")\n",
        "\n",
        "optimizer = tg.TGD(parameters=[answer], engine=eval_engine)\n",
        "evaluation_instruction = (f\"Here's a question: {question_string}. \"\n",
        "                           \"Evaluate any given answer to this question, \"\n",
        "                           \"be smart, logical, and very critical. \"\n",
        "                           \"Just provide concise feedback.\")\n",
        "\n",
        "\n",
        "# TextLoss is a natural-language specified loss function that describes\n",
        "# how we want to evaluate the reasoning.\n",
        "loss_fn = tg.TextLoss(evaluation_instruction, engine=eval_engine)"
      ],
      "metadata": {
        "id": "e3TE4ZH81q5o"
      },
      "id": "e3TE4ZH81q5o",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.zero_grad()\n",
        "loss = loss_fn(answer)\n",
        "loss.backward(engine=eval_engine)\n",
        "optimizer.step()\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzBFevE210Zb",
        "outputId": "30f1100e-77a4-4261-bbb9-91456c8e7077"
      },
      "id": "wzBFevE210Zb",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:TextualGradientDescent prompt for update\n",
            "INFO:textgrad:TextualGradientDescent optimizer response\n",
            "INFO:textgrad:TextualGradientDescent updated text\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Variable(value=Assuming a constant drying rate and that the drying capacity is the only limiting factor, it would take approximately 1 hour and 15 minutes to dry 30 shirts. This estimate is based on the given information that it takes 1 hour to dry 25 shirts. However, it's important to note that this is an estimation and real-world conditions may vary. Factors such as changes in weather conditions and shirt materials could affect the drying time. Therefore, while the answer is a good estimate, it's not definitive due to the lack of additional information., role=concise and accurate answer to the question, grads=Here is a conversation:\n",
              "\n",
              "<CONVERSATION><LM_SYSTEM_PROMPT> Here's a question: If it takes 1 hour to dry 25 shirts under the sun, how long will it take to dry 30 shirts under the sun? Reason step by step. Evaluate any given answer to this question, be smart, logical, and very critical. Just provide concise feedback. </LM_SYSTEM_PROMPT>\n",
              "\n",
              "<LM_INPUT> Assuming a constant drying rate and that the drying capacity is the only limiting factor, it would take 1 hour and 15 minutes to dry 30 shirts. This estimate is based on the given information that it takes 1 hour to dry 25 shirts. However, it's important to note that this estimate is based on the assumption of constant drying conditions. Variations in the intensity of the sun, the material of the shirts, and the humidity could lead to different drying times. Without additional information, it's impossible to provide a definitive answer. However, the drying time is likely to be between 1 hour and 15 minutes and 2 hours, depending on these factors. </LM_INPUT>\n",
              "\n",
              "<LM_OUTPUT> The answer provided is logical and reasonable, given the information available. It correctly applies the concept of proportionality, assuming that the drying rate is constant and that the drying capacity is the only limiting factor. However, it's important to note that this is an estimation and real-world conditions may vary. Factors such as changes in sunlight intensity, humidity, and the material of the shirts could affect the drying time. Therefore, while the answer is a good estimate, it's not definitive due to the lack of additional information. </LM_OUTPUT>\n",
              "\n",
              "</CONVERSATION>\n",
              "\n",
              "This conversation is potentially part of a larger system. The output is used as response from the language model\n",
              "\n",
              "Here is the feedback we got for concise and accurate answer to the question in the conversation:\n",
              "\n",
              "<FEEDBACK>The variable provides a well-reasoned and logical response to the question, applying the concept of proportionality to estimate the drying time for 30 shirts. However, there are a few areas where the response could be improved to better meet the objective of being a concise and accurate answer.\n",
              "\n",
              "1. **Clarity and Precision**: The response could be more precise in its language. For instance, instead of saying \"it's important to note that this estimate is based on the assumption of constant drying conditions,\" the variable could state, \"This estimate assumes constant drying conditions.\" This would make the assumption clearer and more concise.\n",
              "\n",
              "2. **Conciseness**: The variable could be more concise in its explanation of the factors that could affect drying time. Instead of listing \"variations in the intensity of the sun, the material of the shirts, and the humidity,\" the variable could simply state, \"weather conditions and shirt materials.\" This would convey the same information in a more concise manner.\n",
              "\n",
              "3. **Specificity**: The variable could be more specific in its estimate of the drying time. Instead of saying \"the drying time is likely to be between 1 hour and 15 minutes and 2 hours,\" the variable could provide a more specific range, such as \"between 1 hour and 15 minutes and 1 hour and 45 minutes.\" This would make the estimate more precise and potentially more useful.\n",
              "\n",
              "4. **Assumptions**: The variable could be more explicit about its assumptions. For instance, it could state, \"Assuming the drying rate is constant and the drying capacity is the only limiting factor, it would take 1 hour and 15 minutes to dry 30 shirts.\" This would make the assumptions clearer and more concise.\n",
              "\n",
              "5. **Limitations**: The variable could be more explicit about the limitations of its estimate. Instead of saying, \"Without additional information, it's impossible to provide a definitive answer,\" the variable could state, \"This estimate is based on the given information and may not be accurate under different drying conditions.\" This would make the limitations of the estimate clearer and more concise.\n",
              "\n",
              "By making these improvements, the variable could provide a more concise and accurate answer to the question, better meeting the objective function.</FEEDBACK>\n",
              "\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the gradient that would improve the next iteration.\n",
        "print(f\"Gradient: {answer.gradients}\")\n",
        "print('---' * 100)\n",
        "print(f\"Value {answer.value}\")\n",
        "print('---' * 100)\n",
        "# How much is the loss\n",
        "print(f\"Loss: {loss.value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDnbca6Z6xGc",
        "outputId": "e10fab87-b0fd-4e24-f88c-357c07da434d"
      },
      "id": "XDnbca6Z6xGc",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient {Variable(value=The variable provides a well-reasoned and logical response to the question, applying the concept of proportionality to estimate the drying time for 30 shirts. However, there are a few areas where the response could be improved to better meet the objective of being a concise and accurate answer.\n",
            "\n",
            "1. **Clarity and Precision**: The response could be more precise in its language. For instance, instead of saying \"it's important to note that this estimate is based on the assumption of constant drying conditions,\" the variable could state, \"This estimate assumes constant drying conditions.\" This would make the assumption clearer and more concise.\n",
            "\n",
            "2. **Conciseness**: The variable could be more concise in its explanation of the factors that could affect drying time. Instead of listing \"variations in the intensity of the sun, the material of the shirts, and the humidity,\" the variable could simply state, \"weather conditions and shirt materials.\" This would convey the same information in a more concise manner.\n",
            "\n",
            "3. **Specificity**: The variable could be more specific in its estimate of the drying time. Instead of saying \"the drying time is likely to be between 1 hour and 15 minutes and 2 hours,\" the variable could provide a more specific range, such as \"between 1 hour and 15 minutes and 1 hour and 45 minutes.\" This would make the estimate more precise and potentially more useful.\n",
            "\n",
            "4. **Assumptions**: The variable could be more explicit about its assumptions. For instance, it could state, \"Assuming the drying rate is constant and the drying capacity is the only limiting factor, it would take 1 hour and 15 minutes to dry 30 shirts.\" This would make the assumptions clearer and more concise.\n",
            "\n",
            "5. **Limitations**: The variable could be more explicit about the limitations of its estimate. Instead of saying, \"Without additional information, it's impossible to provide a definitive answer,\" the variable could state, \"This estimate is based on the given information and may not be accurate under different drying conditions.\" This would make the limitations of the estimate clearer and more concise.\n",
            "\n",
            "By making these improvements, the variable could provide a more concise and accurate answer to the question, better meeting the objective function., role=feedback to concise and accurate answer to the question, grads=)}\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Value Assuming a constant drying rate and that the drying capacity is the only limiting factor, it would take approximately 1 hour and 15 minutes to dry 30 shirts. This estimate is based on the given information that it takes 1 hour to dry 25 shirts. However, it's important to note that this is an estimation and real-world conditions may vary. Factors such as changes in weather conditions and shirt materials could affect the drying time. Therefore, while the answer is a good estimate, it's not definitive due to the lack of additional information.\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Loss: The answer provided is logical and reasonable, given the information available. It correctly applies the concept of proportionality, assuming that the drying rate is constant and that the drying capacity is the only limiting factor. However, it's important to note that this is an estimation and real-world conditions may vary. Factors such as changes in sunlight intensity, humidity, and the material of the shirts could affect the drying time. Therefore, while the answer is a good estimate, it's not definitive due to the lack of additional information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize our computation graph.\n",
        "loss.generate_graph()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "RIi3NdJL7RhG",
        "outputId": "024a1e64-d072-402d-e4d5-a262278dc71d"
      },
      "id": "RIi3NdJL7RhG",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"394pt\" height=\"414pt\"\n viewBox=\"0.00 0.00 394.00 414.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 410)\">\n<title>%3</title>\n<polygon fill=\"lightgrey\" stroke=\"transparent\" points=\"-4,4 -4,-410 390,-410 390,4 -4,4\"/>\n<!-- 137595942642560 -->\n<g id=\"node1\" class=\"node\">\n<title>137595942642560</title>\n<polygon fill=\"lavender\" stroke=\"black\" points=\"284,-158 108,-158 108,0 284,0 284,-158\"/>\n<text text-anchor=\"start\" x=\"119\" y=\"-145.6\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Role: </text>\n<text text-anchor=\"start\" x=\"143\" y=\"-145.6\" font-family=\"Arial\" font-size=\"8.00\"> Response from the language model</text>\n<text text-anchor=\"start\" x=\"119\" y=\"-137.6\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Value: </text>\n<text text-anchor=\"start\" x=\"147\" y=\"-137.6\" font-family=\"Arial\" font-size=\"8.00\"> The answer provided is logical and</text>\n<text text-anchor=\"start\" x=\"136.5\" y=\"-129.6\" font-family=\"Arial\" font-size=\"8.00\">reasonable, given the information</text>\n<text text-anchor=\"start\" x=\"139.5\" y=\"-121.6\" font-family=\"Arial\" font-size=\"8.00\">available. It correctly applies the</text>\n<text text-anchor=\"start\" x=\"132\" y=\"-113.6\" font-family=\"Arial\" font-size=\"8.00\">concept of proportionality, assuming</text>\n<text text-anchor=\"start\" x=\"134\" y=\"-105.6\" font-family=\"Arial\" font-size=\"8.00\">that the drying rate is constant and</text>\n<text text-anchor=\"start\" x=\"136\" y=\"-97.6\" font-family=\"Arial\" font-size=\"8.00\">that the drying capacity is the only</text>\n<text text-anchor=\"start\" x=\"130\" y=\"-89.6\" font-family=\"Arial\" font-size=\"8.00\">limiting factor. However, it&#39;s important</text>\n<text text-anchor=\"start\" x=\"132\" y=\"-81.6\" font-family=\"Arial\" font-size=\"8.00\">to note that this is an estimation and</text>\n<text text-anchor=\"start\" x=\"126\" y=\"-73.6\" font-family=\"Arial\" font-size=\"8.00\">real&#45;world conditions may vary. Factors</text>\n<text text-anchor=\"start\" x=\"131\" y=\"-65.6\" font-family=\"Arial\" font-size=\"8.00\">such as changes in sunlight intensity,</text>\n<text text-anchor=\"start\" x=\"128\" y=\"-57.6\" font-family=\"Arial\" font-size=\"8.00\">humidity, and the material of the shirts</text>\n<text text-anchor=\"start\" x=\"126.5\" y=\"-49.6\" font-family=\"Arial\" font-size=\"8.00\">could affect the drying time. Therefore,</text>\n<text text-anchor=\"start\" x=\"131\" y=\"-41.6\" font-family=\"Arial\" font-size=\"8.00\">while the answer is a good estimate,</text>\n<text text-anchor=\"start\" x=\"136.5\" y=\"-33.6\" font-family=\"Arial\" font-size=\"8.00\">it&#39;s not definitive due to the lack of</text>\n<text text-anchor=\"start\" x=\"156.5\" y=\"-25.6\" font-family=\"Arial\" font-size=\"8.00\">additional information.</text>\n<text text-anchor=\"start\" x=\"176\" y=\"-17.6\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Grad Fn: </text>\n<text text-anchor=\"start\" x=\"213\" y=\"-17.6\" font-family=\"Arial\" font-size=\"8.00\"> </text>\n<text text-anchor=\"start\" x=\"115\" y=\"-9.6\" font-family=\"Arial\" font-size=\"8.00\">textgrad.autograd.llm_ops.LLMCall.backward</text>\n</g>\n<!-- 137595942476176 -->\n<g id=\"node2\" class=\"node\">\n<title>137595942476176</title>\n<polygon fill=\"lavender\" stroke=\"black\" points=\"190,-338 0,-338 0,-172 190,-172 190,-338\"/>\n<text text-anchor=\"start\" x=\"17.5\" y=\"-325.6\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Role: </text>\n<text text-anchor=\"start\" x=\"41.5\" y=\"-325.6\" font-family=\"Arial\" font-size=\"8.00\"> Concise and accurate answer to the</text>\n<text text-anchor=\"start\" x=\"79.5\" y=\"-317.6\" font-family=\"Arial\" font-size=\"8.00\">question</text>\n<text text-anchor=\"start\" x=\"7\" y=\"-309.6\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Value: </text>\n<text text-anchor=\"start\" x=\"35\" y=\"-309.6\" font-family=\"Arial\" font-size=\"8.00\"> Assuming a constant drying rate and that</text>\n<text text-anchor=\"start\" x=\"30\" y=\"-301.6\" font-family=\"Arial\" font-size=\"8.00\">the drying capacity is the only limiting</text>\n<text text-anchor=\"start\" x=\"31.5\" y=\"-293.6\" font-family=\"Arial\" font-size=\"8.00\">factor, it would take approximately 1</text>\n<text text-anchor=\"start\" x=\"29.5\" y=\"-285.6\" font-family=\"Arial\" font-size=\"8.00\">hour and 15 minutes to dry 30 shirts.</text>\n<text text-anchor=\"start\" x=\"32.5\" y=\"-277.6\" font-family=\"Arial\" font-size=\"8.00\">This estimate is based on the given</text>\n<text text-anchor=\"start\" x=\"29.5\" y=\"-269.6\" font-family=\"Arial\" font-size=\"8.00\">information that it takes 1 hour to dry</text>\n<text text-anchor=\"start\" x=\"32.5\" y=\"-261.6\" font-family=\"Arial\" font-size=\"8.00\">25 shirts. However, it&#39;s important to</text>\n<text text-anchor=\"start\" x=\"35.5\" y=\"-253.6\" font-family=\"Arial\" font-size=\"8.00\">note that this is an estimation and</text>\n<text text-anchor=\"start\" x=\"25\" y=\"-245.6\" font-family=\"Arial\" font-size=\"8.00\">real&#45;world conditions may vary. Factors</text>\n<text text-anchor=\"start\" x=\"26.5\" y=\"-237.6\" font-family=\"Arial\" font-size=\"8.00\">such as changes in weather conditions</text>\n<text text-anchor=\"start\" x=\"34\" y=\"-229.6\" font-family=\"Arial\" font-size=\"8.00\">and shirt materials could affect the</text>\n<text text-anchor=\"start\" x=\"22.5\" y=\"-221.6\" font-family=\"Arial\" font-size=\"8.00\">drying time. Therefore, while the answer</text>\n<text text-anchor=\"start\" x=\"32.5\" y=\"-213.6\" font-family=\"Arial\" font-size=\"8.00\">is a good estimate, it&#39;s not definitive</text>\n<text text-anchor=\"start\" x=\"46.5\" y=\"-205.6\" font-family=\"Arial\" font-size=\"8.00\">due to the lack of additional</text>\n<text text-anchor=\"start\" x=\"73.5\" y=\"-197.6\" font-family=\"Arial\" font-size=\"8.00\">information.</text>\n<text text-anchor=\"start\" x=\"75\" y=\"-189.6\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Grad Fn: </text>\n<text text-anchor=\"start\" x=\"112\" y=\"-189.6\" font-family=\"Arial\" font-size=\"8.00\"> </text>\n<text text-anchor=\"start\" x=\"14\" y=\"-181.6\" font-family=\"Arial\" font-size=\"8.00\">textgrad.autograd.llm_ops.LLMCall.backward</text>\n</g>\n<!-- 137595942476176&#45;&gt;137595942642560 -->\n<g id=\"edge1\" class=\"edge\">\n<title>137595942476176&#45;&gt;137595942642560</title>\n<path fill=\"none\" stroke=\"black\" d=\"M142.69,-171.84C143.6,-170.27 144.52,-168.69 145.43,-167.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"148.67,-168.52 150.66,-158.11 142.61,-165 148.67,-168.52\"/>\n</g>\n<!-- 137595942640160 -->\n<g id=\"node3\" class=\"node\">\n<title>137595942640160</title>\n<polygon fill=\"lavender\" stroke=\"black\" points=\"386,-294 208,-294 208,-216 386,-216 386,-294\"/>\n<text text-anchor=\"start\" x=\"224.5\" y=\"-281.6\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Role: </text>\n<text text-anchor=\"start\" x=\"248.5\" y=\"-281.6\" font-family=\"Arial\" font-size=\"8.00\"> System prompt for the evaluation</text>\n<text text-anchor=\"start\" x=\"215\" y=\"-273.6\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Value: </text>\n<text text-anchor=\"start\" x=\"243\" y=\"-273.6\" font-family=\"Arial\" font-size=\"8.00\"> Here&#39;s a question: If it takes 1 hour to</text>\n<text text-anchor=\"start\" x=\"230.5\" y=\"-265.6\" font-family=\"Arial\" font-size=\"8.00\">dry 25 shirts under the sun, how long</text>\n<text text-anchor=\"start\" x=\"234\" y=\"-257.6\" font-family=\"Arial\" font-size=\"8.00\">will it take to dry 30 shirts under the</text>\n<text text-anchor=\"start\" x=\"225.5\" y=\"-249.6\" font-family=\"Arial\" font-size=\"8.00\">sun? Reason step by step. Evaluate any</text>\n<text text-anchor=\"start\" x=\"226\" y=\"-241.6\" font-family=\"Arial\" font-size=\"8.00\">given answer to this question, be smart,</text>\n<text text-anchor=\"start\" x=\"232.5\" y=\"-233.6\" font-family=\"Arial\" font-size=\"8.00\">logical, and very critical. Just provide</text>\n<text text-anchor=\"start\" x=\"265\" y=\"-225.6\" font-family=\"Arial\" font-size=\"8.00\">concise feedback.</text>\n</g>\n<!-- 137595942640160&#45;&gt;137595942642560 -->\n<g id=\"edge2\" class=\"edge\">\n<title>137595942640160&#45;&gt;137595942642560</title>\n<path fill=\"none\" stroke=\"black\" d=\"M274.84,-215.81C266.43,-201.33 256.47,-184.18 246.52,-167.03\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"249.37,-164.97 241.32,-158.08 243.31,-168.48 249.37,-164.97\"/>\n</g>\n<!-- 137595942476224 -->\n<g id=\"node4\" class=\"node\">\n<title>137595942476224</title>\n<polygon fill=\"lavender\" stroke=\"black\" points=\"176,-406 14,-406 14,-352 176,-352 176,-406\"/>\n<text text-anchor=\"start\" x=\"48.5\" y=\"-393.6\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Role: </text>\n<text text-anchor=\"start\" x=\"72.5\" y=\"-393.6\" font-family=\"Arial\" font-size=\"8.00\"> Question to the llm</text>\n<text text-anchor=\"start\" x=\"23.5\" y=\"-385.6\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Value: </text>\n<text text-anchor=\"start\" x=\"51.5\" y=\"-385.6\" font-family=\"Arial\" font-size=\"8.00\"> If it takes 1 hour to dry 25 shirts</text>\n<text text-anchor=\"start\" x=\"29\" y=\"-377.6\" font-family=\"Arial\" font-size=\"8.00\">under the sun, how long will it take to</text>\n<text text-anchor=\"start\" x=\"21\" y=\"-369.6\" font-family=\"Arial\" font-size=\"8.00\">dry 30 shirts under the sun? Reason step</text>\n<text text-anchor=\"start\" x=\"82\" y=\"-361.6\" font-family=\"Arial\" font-size=\"8.00\">by step</text>\n</g>\n<!-- 137595942476224&#45;&gt;137595942476176 -->\n<g id=\"edge3\" class=\"edge\">\n<title>137595942476224&#45;&gt;137595942476176</title>\n<path fill=\"none\" stroke=\"black\" d=\"M95,-351.83C95,-350.78 95,-349.71 95,-348.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"98.5,-348.37 95,-338.37 91.5,-348.37 98.5,-348.37\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7d248d501de0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}