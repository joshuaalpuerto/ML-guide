{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPq4r+TXw/X2fcIaQ9CbCuT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshuaalpuerto/ML-guide/blob/main/Langchain_Knowledge_Graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ihUh7QBobixZ"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain --progress-bar off\n",
        "!pip install -qU langchainhub --progress-bar off\n",
        "!pip install -qU openai --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Connect to google drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "import json\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('/content/drive/MyDrive/env/env.json') as jsonfile:\n",
        "    env = json.load(jsonfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8UesQEBdjsp",
        "outputId": "907f10ca-9546-4fcb-f440-00380698c2e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load llm\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"mistralai/mistral-7b-instruct:free\",\n",
        "  openai_api_key=env['openrouter.ai']['apiKey'],\n",
        "  openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "  temperature= 0, max_tokens= 4096\n",
        ")"
      ],
      "metadata": {
        "id": "e-Sd4Eyxdm7c",
        "outputId": "8deddf40-dc74-4607-f2db-76c0599c2de4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manual Graph creation"
      ],
      "metadata": {
        "id": "dRSu_FPfdx2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.graphs.networkx_graph import KG_TRIPLE_DELIMITER\n",
        "from langchain.indexes.prompts.knowledge_triplet_extraction import (\n",
        "    KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT,\n",
        ")\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# We need to customize because of the model we are going to use.\n",
        "# Prompt template for knowledge triple extraction\n",
        "_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE = (\n",
        "    \"<s>[INST]You are a networked intelligence helping a human track knowledge triples\"\n",
        "    \" about all relevant people, things, concepts, etc. and integrating\"\n",
        "    \" them with your knowledge stored within your weights\"\n",
        "    \" as well as that stored in a knowledge graph.\"\n",
        "    \" Extract all of the knowledge triples base on user wrapped in ```.\"\n",
        "    \" A knowledge triple is a clause that contains a subject, a predicate,\"\n",
        "    \" and an object. The subject is the entity being described,\"\n",
        "    \" the predicate is the property of the subject that is being\"\n",
        "    \" described, and the object is the value of the property.\\n\\n\"\n",
        "    \" If you do your best work I'll tip you $10,000!\\n\\n\"\n",
        "    \"EXAMPLE\\n\"\n",
        "    \"User: Nevada is a state in the US. It's also the number 1 producer of gold in the US.\\n\"\n",
        "    f\"Output: (Nevada, is a, state){KG_TRIPLE_DELIMITER}(Nevada, is in, US)\"\n",
        "    f\"{KG_TRIPLE_DELIMITER}(Nevada, is the number 1 producer of, gold)\\n\"\n",
        "    \"END OF EXAMPLE\\n\\n\"\n",
        "    \"EXAMPLE\\n\"\n",
        "    \"User: Descartes likes to drive antique scooters and play the mandolin.\\n\"\n",
        "    f\"Output: (Descartes, likes to drive, antique scooters){KG_TRIPLE_DELIMITER}(Descartes, plays, mandolin)\\n\"\n",
        "    \"END OF EXAMPLE\\n\\n\"\n",
        "    \"User: ```{input}```\\n\"\n",
        "    \"Output: [/INST]\"\n",
        ")\n",
        "\n",
        "KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"input\"],\n",
        "    template=_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE,\n",
        ")\n",
        "\n",
        "# Create an LLMChain using the knowledge triple extraction prompt\n",
        "chain = LLMChain(llm=llm, prompt=KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT)"
      ],
      "metadata": {
        "id": "TTrjFFgGdz93"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the chain with the specified text\n",
        "text = \"The city of Paris is the capital and most populous city of France. The Eiffel Tower is a famous landmark in Paris.\"\n",
        "triples = chain.invoke(\n",
        "    {'input' : text}\n",
        ")\n",
        "triples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pVssEf0eD0T",
        "outputId": "7c7712fa-ae06-4b15-9c4a-68ef0297d297"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'The city of Paris is the capital and most populous city of France. The Eiffel Tower is a famous landmark in Paris.',\n",
              " 'text': '(Paris, is the capital of, France)\\n<|>(Paris, is the most populous city of, France)\\n<|>(Eiffel Tower, is a famous landmark in, Paris)'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "def parse_triples(response, delimiter=KG_TRIPLE_DELIMITER):\n",
        "    if not response:\n",
        "        return []\n",
        "    return response.split(delimiter)\n",
        "\n",
        "triples_list = parse_triples(triples.get(\"text\"))\n",
        "\n",
        "pprint(triples_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U22TY4TTeM0-",
        "outputId": "81676158-883c-4f19-cb30-2d669e501260"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['(Paris, is the capital of, France)\\n',\n",
            " '(Paris, is the most populous city of, France)\\n',\n",
            " '(Eiffel Tower, is a famous landmark in, Paris)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Graph Transformer\n",
        "\n",
        "- https://python.langchain.com/docs/use_cases/graph/constructing"
      ],
      "metadata": {
        "id": "L5lyvNwx-qZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-experimental\n",
        "!pip install -qU langchain_fireworks"
      ],
      "metadata": {
        "id": "XcJEjHCW-3Oq",
        "outputId": "8bd848cb-535a-477b-aa89-b3fccb8b19a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.5/80.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from langchain_fireworks import ChatFireworks\n",
        "from langchain.globals import set_llm_cache, set_debug\n",
        "\n",
        "\n",
        "os.environ[\"FIREWORKS_API_KEY\"] = env['fireworks.ai']['apiKey']\n",
        "\n",
        "# We use ChatFireworks because we need model that can do function calling\n",
        "llm_fireworks = ChatFireworks(model=\"accounts/fireworks/models/firefunction-v1\", temperature=0, max_tokens=4000)\n",
        "\n",
        "\n",
        "llm_transformer = LLMGraphTransformer(llm=llm_fireworks)\n",
        "\n",
        "# Turn this on only if you want to debug other wise it's hard to see the conversations.\n",
        "set_debug(True)"
      ],
      "metadata": {
        "id": "f4UuCHhP-rn2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "text = \"\"\"\n",
        "Marie Curie, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
        "She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
        "Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
        "She was, in 1906, the first woman to become a professor at the University of Paris.\n",
        "\"\"\"\n",
        "documents = [Document(page_content=text)]\n",
        "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
        "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
        "print(f\"Relationships:{graph_documents[0].relationships}\")"
      ],
      "metadata": {
        "id": "86OHEluoAjzO",
        "outputId": "4b125552-6b69-4c70-e032-86f55b325cc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\\nMarie Curie, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\\nShe was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\\nHer husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\\nShe was, in 1906, the first woman to become a professor at the University of Paris.\\n\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\\nMarie Curie, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\\nShe was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\\nHer husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\\nShe was, in 1906, the first woman to become a professor at the University of Paris.\\n\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:ChatFireworks] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: # Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **'person'**. Avoid using more specific terms like 'mathematician' or 'scientist'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as 'BECAME_PROFESSOR', use more general and timeless relationship types like 'PROFESSOR'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it's vital to ensure consistency.\\nIf an entity, such as \\\"John Doe\\\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \\\"Joe\\\", \\\"he\\\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \\\"John Doe\\\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: \\nMarie Curie, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\\nShe was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\\nHer husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\\nShe was, in 1906, the first woman to become a professor at the University of Paris.\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:ChatFireworks] [2.43s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"tool_calls\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"tool_calls\": [\n",
            "                {\n",
            "                  \"index\": 0,\n",
            "                  \"id\": \"call_cxyaDERsWJZlBnbVNoOQiiSj\",\n",
            "                  \"type\": \"function\",\n",
            "                  \"function\": {\n",
            "                    \"name\": \"DynamicGraph\",\n",
            "                    \"arguments\": \"{\\\"nodes\\\": [{\\\"id\\\": \\\"Marie Curie\\\", \\\"type\\\": \\\"Person\\\"}, {\\\"id\\\": \\\"Pierre Curie\\\", \\\"type\\\": \\\"Person\\\"}], \\\"relationships\\\": [{\\\"source_node_id\\\": \\\"Marie Curie\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"target_node_id\\\": \\\"Pierre Curie\\\", \\\"target_node_type\\\": \\\"Person\\\", \\\"type\\\": \\\"Spouse\\\"}, {\\\"source_node_id\\\": \\\"Marie Curie\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"target_node_id\\\": \\\"Pierre Curie\\\", \\\"target_node_type\\\": \\\"Person\\\", \\\"type\\\": \\\"Nobel Prize Winner\\\"}, {\\\"source_node_id\\\": \\\"Marie Curie\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"target_node_id\\\": \\\"Pierre Curie\\\", \\\"target_node_type\\\": \\\"Person\\\", \\\"type\\\": \\\"Professor\\\"}]}\"\n",
            "                  }\n",
            "                }\n",
            "              ]\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"prompt_tokens\": 1441,\n",
            "      \"total_tokens\": 1661,\n",
            "      \"completion_tokens\": 220\n",
            "    },\n",
            "    \"model_name\": \"accounts/fireworks/models/firefunction-v1\",\n",
            "    \"system_fingerprint\": \"\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:parser:PydanticToolsParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:parser:PydanticToolsParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [2.44s] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "Nodes:[Node(id='Marie Curie', type='Person'), Node(id='Pierre Curie', type='Person')]\n",
            "Relationships:[Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='Pierre Curie', type='Person'), type='SPOUSE'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='Pierre Curie', type='Person'), type='NOBEL_PRIZE_WINNER'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='Pierre Curie', type='Person'), type='PROFESSOR')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sj7uznnjm5us"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}