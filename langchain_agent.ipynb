{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "EaQYcxAa9-gk"
      ],
      "authorship_tag": "ABX9TyOR6iBXCn2Y+cQ0TCDqs3EU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshuaalpuerto/ML-guide/blob/main/langchain_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MNTwluKrBZbf"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain --progress-bar off\n",
        "!pip install -qU langchainhub --progress-bar off\n",
        "!pip install -qU duckduckgo-search --progress-bar off\n",
        "!pip install -qU fireworks-ai --progress-bar off\n",
        "!pip install -qU openai --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title load fireworks API key\n",
        "#connect to google drive\n",
        "from google.colab import drive\n",
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('/content/drive/MyDrive/env/env.json') as jsonfile:\n",
        "    env = json.load(jsonfile)\n",
        "\n",
        "os.environ[\"FIREWORKS_API_KEY\"] = env['fireworks.ai']['apiKey']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK_jTFArFvk7",
        "outputId": "50ec2b0f-4352-4ebb-c502-01a6df7a7a5f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "# This is required to make it work for old version of openai < 1\n",
        "openai.api_base = \"https://api.fireworks.ai/inference/v1\"\n",
        "openai.api_key = env['fireworks.ai']['apiKey']"
      ],
      "metadata": {
        "id": "MvF8EFRQ-fY7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.globals import set_llm_cache, set_debug\n",
        "from langchain.cache import InMemoryCache\n",
        "\n",
        "set_llm_cache(InMemoryCache())\n",
        "# Turn this on only if you want to debug other wise it's hard to see the conversations.\n",
        "set_debug(True)"
      ],
      "metadata": {
        "id": "Lbgcn10nHIuB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain.agents import tool\n",
        "from langchain.tools import BaseTool\n",
        "from typing_extensions import Annotated\n",
        "from typing import Literal, Optional, Type\n",
        "\n",
        "TemperatureUnitSymbol = Literal[\"celcius\", \"fahrenheit\"]\n",
        "\n",
        "class GetCurrentWeatherInput(BaseModel):\n",
        "    location: str = Field(description=\"The city and state, e.g. San Francisco, CA\")\n",
        "    unit: Optional[TemperatureUnitSymbol] = Field(description=\"The temperature unit value\")\n",
        "\n",
        "class GetCurrentWeather(BaseTool):\n",
        "    name = \"get_current_weather\"\n",
        "    description = \"Get the current weather in a given location\"\n",
        "    args_schema: Type[BaseModel] = GetCurrentWeatherInput\n",
        "    return_direct = True\n",
        "\n",
        "    def _run(\n",
        "        self, **payload\n",
        "    ) -> str:\n",
        "      location = payload.get(\"location\")\n",
        "      unit = payload.get(\"unit\")\n",
        "      weather_info = {\n",
        "          \"location\": location,\n",
        "          \"temperature\": \"72\",\n",
        "          \"unit\": unit,\n",
        "          \"forecast\": [\"sunny\", \"windy\"],\n",
        "      }\n",
        "\n",
        "      return f\"Current location in {location} is 72 {unit}\"\n",
        "\n"
      ],
      "metadata": {
        "id": "vdZ7F5YcPwhB"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function calling"
      ],
      "metadata": {
        "id": "EaQYcxAa9-gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.callbacks import StdOutCallbackHandler\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "\n",
        "\n",
        "functions = [get_current_weather]\n",
        "tools = [{ \"type\": \"function\", \"function\": format_tool_to_openai_function(f)} for f in functions]\n",
        "\n",
        "# Initialize a Fireworks chat model\n",
        "# For function calling we cannot use ChatFireworks integration as it doesn't properly pass functions\n",
        "llm = ChatOpenAI(model=\"accounts/fireworks/models/fw-function-call-34b-v0\",\n",
        "                 openai_api_key=env['fireworks.ai']['apiKey'],\n",
        "                 openai_api_base=\"https://api.fireworks.ai/inference/v1\",\n",
        "                 # verbose=True,\n",
        "                 temperature= 0, max_tokens= 1024,\n",
        "                 model_kwargs={ \"tools\":tools }\n",
        "                )\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are very powerful assistant, but don't know current events\",\n",
        "        ),\n",
        "        (\"user\", \"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "BAR5wJNVGW0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
        "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
        "from langchain.schema.output_parser import BaseLLMOutputParser\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.schema.runnable import RunnableLambda\n",
        "from langchain_core.messages import (\n",
        "    AIMessage,\n",
        "    AIMessageChunk,\n",
        "    BaseMessage,\n",
        "    BaseMessageChunk,\n",
        "    ChatMessage,\n",
        "    FunctionMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage,\n",
        "    ToolMessage,\n",
        ")\n",
        "\n",
        "def format_agent_scratchpad_from_intermediate_steps(x):\n",
        "  return format_to_openai_tool_messages(x[\"intermediate_steps\"])\n",
        "\n",
        "# having error when calling convert_message_to_dict from langchain (https://github.com/langchain-ai/langchain/blob/4c47f39fcb539fdeff6dd6d9b1f483cd9a1af69b/libs/community/langchain_community/adapters/openai.py#L104C5-L104C28)\n",
        "# because when we use tool we are also submitting that to openai (with 'name' in payload which fireworks is not supported yet).\n",
        "# By default langchain also send functions/tools as role to openai.\n",
        "# fireworks doesn't support that so we are going to adjust the prompt\n",
        "def prepare_prompt_for_llm(x):\n",
        "  messages = []\n",
        "  print('prepare_prompt_for_llm')\n",
        "  for message in x.messages:\n",
        "    if isinstance(message, ToolMessage):\n",
        "      # remove the name as we don't want to pass that in fireworks.\n",
        "      message = ToolMessage(content=message.content, tool_call_id=message.tool_call_id)\n",
        "\n",
        "    messages.append(message)\n",
        "\n",
        "\n",
        "  print(messages)\n",
        "  return messages\n",
        "\n",
        "\n",
        "agent = {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"agent_scratchpad\": lambda x: format_agent_scratchpad_from_intermediate_steps(x),\n",
        "    } | prompt | RunnableLambda(prepare_prompt_for_llm) | llm | OpenAIToolsAgentOutputParser()\n",
        "\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=[get_current_weather], verbose=True)\n",
        "\n",
        "\n",
        "agent_executor.invoke({\"input\": \"what is the weather is sf?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BH9Q69_PKp6",
        "outputId": "f1d5d403-6b1e-4366-e48a-b752b573e6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\",\n",
            "  \"intermediate_steps\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableParallel<input,agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\",\n",
            "  \"intermediate_steps\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableParallel<input,agent_scratchpad> > 4:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\",\n",
            "  \"intermediate_steps\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableParallel<input,agent_scratchpad> > 4:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"what is the weather is sf?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableParallel<input,agent_scratchpad> > 5:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\",\n",
            "  \"intermediate_steps\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableParallel<input,agent_scratchpad> > 5:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableParallel<input,agent_scratchpad>] [6ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\",\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\",\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"prompts\",\n",
            "    \"chat\",\n",
            "    \"ChatPromptValue\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"SystemMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"You are very powerful assistant, but don't know current events\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"HumanMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"what is the weather is sf?\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:chain:prepare_prompt_for_llm] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "prepare_prompt_for_llm\n",
            "[SystemMessage(content=\"You are very powerful assistant, but don't know current events\"), HumanMessage(content='what is the weather is sf?')]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:chain:prepare_prompt_for_llm] [2ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": [\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"SystemMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"content\": \"You are very powerful assistant, but don't know current events\",\n",
            "        \"additional_kwargs\": {}\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"HumanMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"content\": \"what is the weather is sf?\",\n",
            "        \"additional_kwargs\": {}\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are very powerful assistant, but don't know current events\\nHuman: what is the weather is sf?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:llm:ChatOpenAI] [1ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"tool_calls\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"tool_calls\": [\n",
            "                {\n",
            "                  \"id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\",\n",
            "                  \"function\": {\n",
            "                    \"arguments\": \"{\\\"location\\\": \\\"sf\\\", \\\"unit\\\": \\\"fahrenheit\\\"}\",\n",
            "                    \"name\": \"get_current_weather\"\n",
            "                  },\n",
            "                  \"type\": \"function\",\n",
            "                  \"index\": 0\n",
            "                }\n",
            "              ]\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 9:parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 9:parser:OpenAIToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": [\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"agent\",\n",
            "        \"OpenAIToolAgentAction\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"tool\": \"get_current_weather\",\n",
            "        \"tool_input\": {\n",
            "          \"location\": \"sf\",\n",
            "          \"unit\": \"fahrenheit\"\n",
            "        },\n",
            "        \"log\": \"\\nInvoking: `get_current_weather` with `{'location': 'sf', 'unit': 'fahrenheit'}`\\n\\n\\n\",\n",
            "        \"message_log\": [\n",
            "          {\n",
            "            \"lc\": 1,\n",
            "            \"type\": \"constructor\",\n",
            "            \"id\": [\n",
            "              \"langchain\",\n",
            "              \"schema\",\n",
            "              \"messages\",\n",
            "              \"AIMessage\"\n",
            "            ],\n",
            "            \"kwargs\": {\n",
            "              \"content\": \"\",\n",
            "              \"additional_kwargs\": {\n",
            "                \"tool_calls\": [\n",
            "                  {\n",
            "                    \"id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\",\n",
            "                    \"function\": {\n",
            "                      \"arguments\": \"{\\\"location\\\": \\\"sf\\\", \\\"unit\\\": \\\"fahrenheit\\\"}\",\n",
            "                      \"name\": \"get_current_weather\"\n",
            "                    },\n",
            "                    \"type\": \"function\",\n",
            "                    \"index\": 0\n",
            "                  }\n",
            "                ]\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        ],\n",
            "        \"tool_call_id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] [17ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:tool:get_current_weather] Entering Tool run with input:\n",
            "\u001b[0m\"{'location': 'sf', 'unit': 'fahrenheit'}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:tool:get_current_weather] [1ms] Exiting Tool run with output:\n",
            "\u001b[0m\"Current location in sf is 72 fahrenheit\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableParallel<input,agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableParallel<input,agent_scratchpad> > 13:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableParallel<input,agent_scratchpad> > 13:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"what is the weather is sf?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableParallel<input,agent_scratchpad> > 14:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableParallel<input,agent_scratchpad> > 14:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": [\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"AIMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"content\": \"\",\n",
            "        \"additional_kwargs\": {\n",
            "          \"tool_calls\": [\n",
            "            {\n",
            "              \"id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\",\n",
            "              \"function\": {\n",
            "                \"arguments\": \"{\\\"location\\\": \\\"sf\\\", \\\"unit\\\": \\\"fahrenheit\\\"}\",\n",
            "                \"name\": \"get_current_weather\"\n",
            "              },\n",
            "              \"type\": \"function\",\n",
            "              \"index\": 0\n",
            "            }\n",
            "          ]\n",
            "        }\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"ToolMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"tool_call_id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\",\n",
            "        \"content\": \"Current location in sf is 72 fahrenheit\",\n",
            "        \"additional_kwargs\": {\n",
            "          \"name\": \"get_current_weather\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableParallel<input,agent_scratchpad>] [6ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 15:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 15:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"prompts\",\n",
            "    \"chat\",\n",
            "    \"ChatPromptValue\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"SystemMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"You are very powerful assistant, but don't know current events\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"HumanMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"what is the weather is sf?\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"AIMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"\",\n",
            "          \"additional_kwargs\": {\n",
            "            \"tool_calls\": [\n",
            "              {\n",
            "                \"id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\",\n",
            "                \"function\": {\n",
            "                  \"arguments\": \"{\\\"location\\\": \\\"sf\\\", \\\"unit\\\": \\\"fahrenheit\\\"}\",\n",
            "                  \"name\": \"get_current_weather\"\n",
            "                },\n",
            "                \"type\": \"function\",\n",
            "                \"index\": 0\n",
            "              }\n",
            "            ]\n",
            "          }\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"ToolMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"tool_call_id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\",\n",
            "          \"content\": \"Current location in sf is 72 fahrenheit\",\n",
            "          \"additional_kwargs\": {\n",
            "            \"name\": \"get_current_weather\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 16:chain:prepare_prompt_for_llm] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "prepare_prompt_for_llm\n",
            "[SystemMessage(content=\"You are very powerful assistant, but don't know current events\"), HumanMessage(content='what is the weather is sf?'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ByENVAlPvpTBvqqrr0vTAfCv', 'function': {'arguments': '{\"location\": \"sf\", \"unit\": \"fahrenheit\"}', 'name': 'get_current_weather'}, 'type': 'function', 'index': 0}]}), ToolMessage(content='Current location in sf is 72 fahrenheit', tool_call_id='call_ByENVAlPvpTBvqqrr0vTAfCv')]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 16:chain:prepare_prompt_for_llm] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": [\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"SystemMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"content\": \"You are very powerful assistant, but don't know current events\",\n",
            "        \"additional_kwargs\": {}\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"HumanMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"content\": \"what is the weather is sf?\",\n",
            "        \"additional_kwargs\": {}\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"AIMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"content\": \"\",\n",
            "        \"additional_kwargs\": {\n",
            "          \"tool_calls\": [\n",
            "            {\n",
            "              \"id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\",\n",
            "              \"function\": {\n",
            "                \"arguments\": \"{\\\"location\\\": \\\"sf\\\", \\\"unit\\\": \\\"fahrenheit\\\"}\",\n",
            "                \"name\": \"get_current_weather\"\n",
            "              },\n",
            "              \"type\": \"function\",\n",
            "              \"index\": 0\n",
            "            }\n",
            "          ]\n",
            "        }\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"ToolMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"content\": \"Current location in sf is 72 fahrenheit\",\n",
            "        \"tool_call_id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 17:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are very powerful assistant, but don't know current events\\nHuman: what is the weather is sf?\\nAI: \\nTool: Current location in sf is 72 fahrenheit\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 17:llm:ChatOpenAI] [825ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"The current weather in sf is 72 fahrenheit. \",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"The current weather in sf is 72 fahrenheit. \",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 15,\n",
            "      \"prompt_tokens\": 319,\n",
            "      \"total_tokens\": 334\n",
            "    },\n",
            "    \"model_name\": \"accounts/fireworks/models/fw-function-call-34b-v0\",\n",
            "    \"system_fingerprint\": null\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 18:parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 18:parser:OpenAIToolsAgentOutputParser] [2ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"schema\",\n",
            "    \"agent\",\n",
            "    \"AgentFinish\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"return_values\": {\n",
            "      \"output\": \"The current weather in sf is 72 fahrenheit. \"\n",
            "    },\n",
            "    \"log\": \"The current weather in sf is 72 fahrenheit. \"\n",
            "  }\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence] [841ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [871ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"The current weather in sf is 72 fahrenheit. \"\n",
            "}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'what is the weather is sf?',\n",
              " 'output': 'The current weather in sf is 72 fahrenheit. '}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regular LLM"
      ],
      "metadata": {
        "id": "cFDUS084-EF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import Fireworks\n",
        "llm = Fireworks(\n",
        "          fireworks_api_key=env['fireworks.ai']['apiKey'],\n",
        "          model=\"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
        "          model_kwargs={\"temperature\": 0, \"max_tokens\": 4096},\n",
        "      )"
      ],
      "metadata": {
        "id": "U39jfmwAEG0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "REACT_PROMPT = \"\"\"\n",
        "Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "Thought:{agent_scratchpad}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "          input_variables=[\"tools\", \"tool_name\", \"input\", \"agent_scratchpad\"],\n",
        "          template=REACT_PROMPT,\n",
        "      )"
      ],
      "metadata": {
        "id": "Z1eKG3Rn-GUo"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain.tools.render import render_text_description_and_args\n",
        "\n",
        "tools = [GetCurrentWeather()]\n",
        "\n",
        "# We don't use `create_tool_calling_agent` because Mistral doesn't support tool calling (unless we use fire function)\n",
        "# Instead we use regular `create_react_agent`\n",
        "react_agent = create_react_agent(llm=llm, tools=tools, prompt=prompt, output_parser=None, tools_renderer=render_text_description_and_args)\n",
        "\n",
        "# executes the logical steps we created\n",
        "agent_executor = AgentExecutor(\n",
        "  agent=react_agent,\n",
        "  tools=tools,\n",
        "  verbose=True,\n",
        "  handle_parsing_errors=True,\n",
        "  max_iterations = 5 # useful when agent is stuck in a loop\n",
        ")"
      ],
      "metadata": {
        "id": "Adz2Zoai-Tqh"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\"input\": \"what is the weather is sf?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xGBPfupJC2s4",
        "outputId": "69c434be-b0af-480b-b04f-31df6ac6b364"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"agent_scratchpad\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] [9ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\",\n",
            "  \"intermediate_steps\": [],\n",
            "  \"agent_scratchpad\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:PromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\",\n",
            "  \"intermediate_steps\": [],\n",
            "  \"agent_scratchpad\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:Fireworks] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Answer the following questions as best you can. You have access to the following tools:\\n\\nget_current_weather: Get the current weather in a given location, args: {'location': {'description': 'The city and state, e.g. San Francisco, CA', 'title': 'Location', 'type': 'string'}, 'unit': {'anyOf': [{'enum': ['celcius', 'fahrenheit'], 'type': 'string'}, {'type': 'null'}], 'description': 'The temperature unit value', 'title': 'Unit'}}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [get_current_weather]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: what is the weather is sf?\\nThought:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:Fireworks] [495ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"The user is asking about the current weather in San Francisco. I need to use the get_current_weather function to get this information.\\nAction:\\nget_current_weather\\nAction Input:\\n{'location': 'San Francisco, CA', 'unit': 'fahrenheit'}\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"Generation\"\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:ReActSingleInputOutputParser] Entering Parser run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"The user is asking about the current weather in San Francisco. I need to use the get_current_weather function to get this information.\\nAction:\\nget_current_weather\\nAction Input:\\n{'location': 'San Francisco, CA', 'unit': 'fahrenheit'}\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:ReActSingleInputOutputParser] [2ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] [516ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:get_current_weather] Entering Tool run with input:\n",
            "\u001b[0m\"{'location': 'San Francisco, CA', 'unit': 'fahrenheit'}\"\n",
            "\u001b[31;1m\u001b[1;3m[tool/error]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:get_current_weather] [1ms] \u001b[0mTool run errored with error:\n",
            "1 validation error for GetCurrentWeatherInput\n",
            "unit\n",
            "  Field required [type=missing, input_value={'location': \"{'location'... 'unit': 'fahrenheit'}\"}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.7/v/missingTraceback (most recent call last):\n",
            "\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/tools.py\", line 404, in run\n",
            "    parsed_input = self._parse_input(tool_input)\n",
            "\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/tools.py\", line 298, in _parse_input\n",
            "    input_args.validate({key_: tool_input})\n",
            "\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pydantic/main.py\", line 1325, in validate\n",
            "    return cls.model_validate(value)\n",
            "\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pydantic/main.py\", line 532, in model_validate\n",
            "    return cls.__pydantic_validator__.validate_python(\n",
            "\n",
            "\n",
            "pydantic_core._pydantic_core.ValidationError: 1 validation error for GetCurrentWeatherInput\n",
            "unit\n",
            "  Field required [type=missing, input_value={'location': \"{'location'... 'unit': 'fahrenheit'}\"}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.7/v/missing\n",
            "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [529ms] Chain run errored with error:\n",
            "\u001b[0m\"1 validation error for GetCurrentWeatherInput\\nunit\\n  Field required [type=missing, input_value={'location': \\\"{'location'... 'unit': 'fahrenheit'}\\\"}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.7/v/missingTraceback (most recent call last):\\n\\n\\n  File \\\"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\\\", line 153, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\\\", line 1432, in _call\\n    next_step_output = self._take_next_step(\\n\\n\\n  File \\\"/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\\\", line 1138, in _take_next_step\\n    [\\n\\n\\n  File \\\"/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\\\", line 1138, in <listcomp>\\n    [\\n\\n\\n  File \\\"/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\\\", line 1223, in _iter_next_step\\n    yield self._perform_agent_action(\\n\\n\\n  File \\\"/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\\\", line 1245, in _perform_agent_action\\n    observation = tool.run(\\n\\n\\n  File \\\"/usr/local/lib/python3.10/dist-packages/langchain_core/tools.py\\\", line 450, in run\\n    raise e\\n\\n\\n  File \\\"/usr/local/lib/python3.10/dist-packages/langchain_core/tools.py\\\", line 404, in run\\n    parsed_input = self._parse_input(tool_input)\\n\\n\\n  File \\\"/usr/local/lib/python3.10/dist-packages/langchain_core/tools.py\\\", line 298, in _parse_input\\n    input_args.validate({key_: tool_input})\\n\\n\\n  File \\\"/usr/local/lib/python3.10/dist-packages/pydantic/main.py\\\", line 1325, in validate\\n    return cls.model_validate(value)\\n\\n\\n  File \\\"/usr/local/lib/python3.10/dist-packages/pydantic/main.py\\\", line 532, in model_validate\\n    return cls.__pydantic_validator__.validate_python(\\n\\n\\npydantic_core._pydantic_core.ValidationError: 1 validation error for GetCurrentWeatherInput\\nunit\\n  Field required [type=missing, input_value={'location': \\\"{'location'... 'unit': 'fahrenheit'}\\\"}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.7/v/missing\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for GetCurrentWeatherInput\nunit\n  Field required [type=missing, input_value={'location': \"{'location'... 'unit': 'fahrenheit'}\"}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-e63b574257e4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"what is the weather is sf?\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             outputs = (\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1433\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1137\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1138\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1139\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                 for a in self._iter_next_step(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1137\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1138\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1139\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                 for a in self._iter_next_step(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1221\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0magent_action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0magent_action\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m             yield self._perform_agent_action(\n\u001b[0m\u001b[1;32m   1224\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_perform_agent_action\u001b[0;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[1;32m   1243\u001b[0m                 \u001b[0mtool_run_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"llm_prefix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0;31m# We then call the tool on the tool input to get an observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1245\u001b[0;31m             observation = tool.run(\n\u001b[0m\u001b[1;32m   1246\u001b[0m                 \u001b[0magent_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/tools.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/tools.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_child_runnable_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mparsed_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m             \u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_args_and_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             observation = (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/tools.py\u001b[0m in \u001b[0;36m_parse_input\u001b[0;34m(self, tool_input)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mkey_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m                 \u001b[0minput_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtool_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtool_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0;34m'The `validate` method is deprecated; use `model_validate` instead.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPydanticDeprecatedSince20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         )\n\u001b[0;32m-> 1325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36mmodel_validate\u001b[0;34m(cls, obj, strict, from_attributes, context)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         return cls.__pydantic_validator__.validate_python(\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_attributes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         )\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for GetCurrentWeatherInput\nunit\n  Field required [type=missing, input_value={'location': \"{'location'... 'unit': 'fahrenheit'}\"}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing"
          ]
        }
      ]
    }
  ]
}