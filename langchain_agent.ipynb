{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "EaQYcxAa9-gk"
      ],
      "authorship_tag": "ABX9TyMrGYgrGH8aVM4y7iEHpj9S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshuaalpuerto/ML-guide/blob/main/langchain_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MNTwluKrBZbf"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain --progress-bar off\n",
        "!pip install -qU langchainhub --progress-bar off\n",
        "!pip install -qU duckduckgo-search --progress-bar off\n",
        "!pip install -qU fireworks-ai --progress-bar off\n",
        "!pip install -qU openai --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title load fireworks API key\n",
        "#connect to google drive\n",
        "from google.colab import drive\n",
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('/content/drive/MyDrive/env/env.json') as jsonfile:\n",
        "    env = json.load(jsonfile)\n",
        "\n",
        "os.environ[\"FIREWORKS_API_KEY\"] = env['fireworks.ai']['apiKey']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK_jTFArFvk7",
        "outputId": "30999e57-6586-4211-bebc-3db5cccd874a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "# This is required to make it work for old version of openai < 1\n",
        "openai.api_base = \"https://api.fireworks.ai/inference/v1\"\n",
        "openai.api_key = env['fireworks.ai']['apiKey']"
      ],
      "metadata": {
        "id": "MvF8EFRQ-fY7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.globals import set_llm_cache, set_debug\n",
        "from langchain.cache import InMemoryCache\n",
        "\n",
        "set_llm_cache(InMemoryCache())\n",
        "# Turn this on only if you want to debug other wise it's hard to see the conversations.\n",
        "set_debug(True)"
      ],
      "metadata": {
        "id": "Lbgcn10nHIuB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain.agents import tool\n",
        "from langchain.tools import BaseTool\n",
        "from typing_extensions import Annotated\n",
        "from typing import Literal, Optional, Type\n",
        "\n",
        "TemperatureUnitSymbol = Literal[\"celcius\", \"fahrenheit\"]\n",
        "\n",
        "class GetCurrentWeatherInput(BaseModel):\n",
        "    location: str = Field(description=\"The city and state, e.g. San Francisco, CA\")\n",
        "    unit: Optional[TemperatureUnitSymbol] = Field(description=\"The temperature unit value\")\n",
        "\n",
        "class GetCurrentWeather(BaseTool):\n",
        "    name = \"get_current_weather\"\n",
        "    description = \"Get the current weather in a given location\"\n",
        "    args_schema: Type[BaseModel] = GetCurrentWeatherInput\n",
        "    return_direct = True\n",
        "\n",
        "    def _run(\n",
        "        self, **payload\n",
        "    ) -> str:\n",
        "\n",
        "      location = payload.get(\"location\")\n",
        "      unit = payload.get(\"unit\")\n",
        "      weather_info = {\n",
        "          \"location\": location,\n",
        "          \"temperature\": \"72\",\n",
        "          \"unit\": unit,\n",
        "          \"forecast\": [\"sunny\", \"windy\"],\n",
        "      }\n",
        "\n",
        "      return f\"Current location in {location} is 72 {unit}\"\n",
        "\n",
        "class GetFlightOffersInput(BaseModel):\n",
        "    originLocationCode: str = Field(\n",
        "        description=\"City/airport IATA code from which the traveler will depart, e.g., BOS for Boston (Required)\"\n",
        "    )\n",
        "    destinationLocationCode: str = Field(\n",
        "        description=\"City/airport IATA code to which the traveler is going, e.g., PAR for Paris (Required)\"\n",
        "    )\n",
        "    departureDate: str = Field(\n",
        "        description=\"The date on which the traveler will depart from the origin to go to the destination, in YYYY-MM-DD format (Required)\"\n",
        "    )\n",
        "    returnDate: str = Field(\n",
        "        description=\"The date on which the traveler will depart from the destination to return to the origin, in YYYY-MM-DD format\"\n",
        "    )\n",
        "    adults: int = Field(\n",
        "        description=\"The number of adult travelers (age 12 or older on the date of departure) (Required)\"\n",
        "    )\n",
        "\n",
        "\n",
        "class GetFlightOffers(BaseTool):\n",
        "    name = \"get_flights_offer\"\n",
        "    description = \"Search for flight information\"\n",
        "    args_schema: Type[BaseModel] = GetFlightOffersInput\n",
        "\n",
        "    def _run(\n",
        "        self, **payload\n",
        "    ) -> str:\n",
        "      adults = payload.get(\"adults\", 1)\n",
        "      return_date = payload.get(\"returnDate\", None)\n",
        "      # Set up the parameters for the request\n",
        "      params = {\n",
        "          **payload,\n",
        "          \"adults\": adults,\n",
        "          \"returnDate\": return_date,\n",
        "          \"currencyCode\": \"EUR\",\n",
        "          \"max\": 5,\n",
        "      }\n",
        "\n",
        "      # Remove None values\n",
        "      params = {k: v for k, v in params.items() if v is not None}\n",
        "\n",
        "\n",
        "      return (\n",
        "          f\"The cheapest price from {params.get('originLocationCode')} to {params.get('destinationLocationCode')} \"\n",
        "          f\"given the dates {params.get('departureDate')} - {params.get('returnDate')} is 500 {params.get('currencyCode')}.\"\n",
        "      )"
      ],
      "metadata": {
        "id": "vdZ7F5YcPwhB"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function calling"
      ],
      "metadata": {
        "id": "EaQYcxAa9-gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.callbacks import StdOutCallbackHandler\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "\n",
        "\n",
        "functions = [get_current_weather]\n",
        "tools = [{ \"type\": \"function\", \"function\": format_tool_to_openai_function(f)} for f in functions]\n",
        "\n",
        "# Initialize a Fireworks chat model\n",
        "# For function calling we cannot use ChatFireworks integration as it doesn't properly pass functions\n",
        "llm = ChatOpenAI(model=\"accounts/fireworks/models/fw-function-call-34b-v0\",\n",
        "                 openai_api_key=env['fireworks.ai']['apiKey'],\n",
        "                 openai_api_base=\"https://api.fireworks.ai/inference/v1\",\n",
        "                 # verbose=True,\n",
        "                 temperature= 0, max_tokens= 1024,\n",
        "                 model_kwargs={ \"tools\":tools }\n",
        "                )\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are very powerful assistant, but don't know current events\",\n",
        "        ),\n",
        "        (\"user\", \"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "BAR5wJNVGW0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
        "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
        "from langchain.schema.output_parser import BaseLLMOutputParser\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.schema.runnable import RunnableLambda\n",
        "from langchain_core.messages import (\n",
        "    AIMessage,\n",
        "    AIMessageChunk,\n",
        "    BaseMessage,\n",
        "    BaseMessageChunk,\n",
        "    ChatMessage,\n",
        "    FunctionMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage,\n",
        "    ToolMessage,\n",
        ")\n",
        "\n",
        "def format_agent_scratchpad_from_intermediate_steps(x):\n",
        "  return format_to_openai_tool_messages(x[\"intermediate_steps\"])\n",
        "\n",
        "# having error when calling convert_message_to_dict from langchain (https://github.com/langchain-ai/langchain/blob/4c47f39fcb539fdeff6dd6d9b1f483cd9a1af69b/libs/community/langchain_community/adapters/openai.py#L104C5-L104C28)\n",
        "# because when we use tool we are also submitting that to openai (with 'name' in payload which fireworks is not supported yet).\n",
        "# By default langchain also send functions/tools as role to openai.\n",
        "# fireworks doesn't support that so we are going to adjust the prompt\n",
        "def prepare_prompt_for_llm(x):\n",
        "  messages = []\n",
        "  print('prepare_prompt_for_llm')\n",
        "  for message in x.messages:\n",
        "    if isinstance(message, ToolMessage):\n",
        "      # remove the name as we don't want to pass that in fireworks.\n",
        "      message = ToolMessage(content=message.content, tool_call_id=message.tool_call_id)\n",
        "\n",
        "    messages.append(message)\n",
        "\n",
        "\n",
        "  print(messages)\n",
        "  return messages\n",
        "\n",
        "\n",
        "agent = {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"agent_scratchpad\": lambda x: format_agent_scratchpad_from_intermediate_steps(x),\n",
        "    } | prompt | RunnableLambda(prepare_prompt_for_llm) | llm | OpenAIToolsAgentOutputParser()\n",
        "\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=[get_current_weather], verbose=True)\n",
        "\n",
        "\n",
        "agent_executor.invoke({\"input\": \"what is the weather is sf?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BH9Q69_PKp6",
        "outputId": "f1d5d403-6b1e-4366-e48a-b752b573e6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\",\n",
            "  \"intermediate_steps\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableParallel<input,agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\",\n",
            "  \"intermediate_steps\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableParallel<input,agent_scratchpad> > 4:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\",\n",
            "  \"intermediate_steps\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableParallel<input,agent_scratchpad> > 4:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"what is the weather is sf?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableParallel<input,agent_scratchpad> > 5:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\",\n",
            "  \"intermediate_steps\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableParallel<input,agent_scratchpad> > 5:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableParallel<input,agent_scratchpad>] [6ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\",\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"what is the weather is sf?\",\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"prompts\",\n",
            "    \"chat\",\n",
            "    \"ChatPromptValue\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"SystemMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"You are very powerful assistant, but don't know current events\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"HumanMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"what is the weather is sf?\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:chain:prepare_prompt_for_llm] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "prepare_prompt_for_llm\n",
            "[SystemMessage(content=\"You are very powerful assistant, but don't know current events\"), HumanMessage(content='what is the weather is sf?')]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:chain:prepare_prompt_for_llm] [2ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": [\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"SystemMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"content\": \"You are very powerful assistant, but don't know current events\",\n",
            "        \"additional_kwargs\": {}\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"HumanMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"content\": \"what is the weather is sf?\",\n",
            "        \"additional_kwargs\": {}\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are very powerful assistant, but don't know current events\\nHuman: what is the weather is sf?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:llm:ChatOpenAI] [1ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"tool_calls\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"tool_calls\": [\n",
            "                {\n",
            "                  \"id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\",\n",
            "                  \"function\": {\n",
            "                    \"arguments\": \"{\\\"location\\\": \\\"sf\\\", \\\"unit\\\": \\\"fahrenheit\\\"}\",\n",
            "                    \"name\": \"get_current_weather\"\n",
            "                  },\n",
            "                  \"type\": \"function\",\n",
            "                  \"index\": 0\n",
            "                }\n",
            "              ]\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 9:parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 9:parser:OpenAIToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": [\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"agent\",\n",
            "        \"OpenAIToolAgentAction\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"tool\": \"get_current_weather\",\n",
            "        \"tool_input\": {\n",
            "          \"location\": \"sf\",\n",
            "          \"unit\": \"fahrenheit\"\n",
            "        },\n",
            "        \"log\": \"\\nInvoking: `get_current_weather` with `{'location': 'sf', 'unit': 'fahrenheit'}`\\n\\n\\n\",\n",
            "        \"message_log\": [\n",
            "          {\n",
            "            \"lc\": 1,\n",
            "            \"type\": \"constructor\",\n",
            "            \"id\": [\n",
            "              \"langchain\",\n",
            "              \"schema\",\n",
            "              \"messages\",\n",
            "              \"AIMessage\"\n",
            "            ],\n",
            "            \"kwargs\": {\n",
            "              \"content\": \"\",\n",
            "              \"additional_kwargs\": {\n",
            "                \"tool_calls\": [\n",
            "                  {\n",
            "                    \"id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\",\n",
            "                    \"function\": {\n",
            "                      \"arguments\": \"{\\\"location\\\": \\\"sf\\\", \\\"unit\\\": \\\"fahrenheit\\\"}\",\n",
            "                      \"name\": \"get_current_weather\"\n",
            "                    },\n",
            "                    \"type\": \"function\",\n",
            "                    \"index\": 0\n",
            "                  }\n",
            "                ]\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        ],\n",
            "        \"tool_call_id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] [17ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:tool:get_current_weather] Entering Tool run with input:\n",
            "\u001b[0m\"{'location': 'sf', 'unit': 'fahrenheit'}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:tool:get_current_weather] [1ms] Exiting Tool run with output:\n",
            "\u001b[0m\"Current location in sf is 72 fahrenheit\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableParallel<input,agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableParallel<input,agent_scratchpad> > 13:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableParallel<input,agent_scratchpad> > 13:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"what is the weather is sf?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableParallel<input,agent_scratchpad> > 14:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableParallel<input,agent_scratchpad> > 14:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": [\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"AIMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"content\": \"\",\n",
            "        \"additional_kwargs\": {\n",
            "          \"tool_calls\": [\n",
            "            {\n",
            "              \"id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\",\n",
            "              \"function\": {\n",
            "                \"arguments\": \"{\\\"location\\\": \\\"sf\\\", \\\"unit\\\": \\\"fahrenheit\\\"}\",\n",
            "                \"name\": \"get_current_weather\"\n",
            "              },\n",
            "              \"type\": \"function\",\n",
            "              \"index\": 0\n",
            "            }\n",
            "          ]\n",
            "        }\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"ToolMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"tool_call_id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\",\n",
            "        \"content\": \"Current location in sf is 72 fahrenheit\",\n",
            "        \"additional_kwargs\": {\n",
            "          \"name\": \"get_current_weather\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableParallel<input,agent_scratchpad>] [6ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 15:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 15:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"prompts\",\n",
            "    \"chat\",\n",
            "    \"ChatPromptValue\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"SystemMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"You are very powerful assistant, but don't know current events\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"HumanMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"what is the weather is sf?\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"AIMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"\",\n",
            "          \"additional_kwargs\": {\n",
            "            \"tool_calls\": [\n",
            "              {\n",
            "                \"id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\",\n",
            "                \"function\": {\n",
            "                  \"arguments\": \"{\\\"location\\\": \\\"sf\\\", \\\"unit\\\": \\\"fahrenheit\\\"}\",\n",
            "                  \"name\": \"get_current_weather\"\n",
            "                },\n",
            "                \"type\": \"function\",\n",
            "                \"index\": 0\n",
            "              }\n",
            "            ]\n",
            "          }\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"ToolMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"tool_call_id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\",\n",
            "          \"content\": \"Current location in sf is 72 fahrenheit\",\n",
            "          \"additional_kwargs\": {\n",
            "            \"name\": \"get_current_weather\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 16:chain:prepare_prompt_for_llm] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "prepare_prompt_for_llm\n",
            "[SystemMessage(content=\"You are very powerful assistant, but don't know current events\"), HumanMessage(content='what is the weather is sf?'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ByENVAlPvpTBvqqrr0vTAfCv', 'function': {'arguments': '{\"location\": \"sf\", \"unit\": \"fahrenheit\"}', 'name': 'get_current_weather'}, 'type': 'function', 'index': 0}]}), ToolMessage(content='Current location in sf is 72 fahrenheit', tool_call_id='call_ByENVAlPvpTBvqqrr0vTAfCv')]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 16:chain:prepare_prompt_for_llm] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": [\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"SystemMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"content\": \"You are very powerful assistant, but don't know current events\",\n",
            "        \"additional_kwargs\": {}\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"HumanMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"content\": \"what is the weather is sf?\",\n",
            "        \"additional_kwargs\": {}\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"AIMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"content\": \"\",\n",
            "        \"additional_kwargs\": {\n",
            "          \"tool_calls\": [\n",
            "            {\n",
            "              \"id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\",\n",
            "              \"function\": {\n",
            "                \"arguments\": \"{\\\"location\\\": \\\"sf\\\", \\\"unit\\\": \\\"fahrenheit\\\"}\",\n",
            "                \"name\": \"get_current_weather\"\n",
            "              },\n",
            "              \"type\": \"function\",\n",
            "              \"index\": 0\n",
            "            }\n",
            "          ]\n",
            "        }\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"lc\": 1,\n",
            "      \"type\": \"constructor\",\n",
            "      \"id\": [\n",
            "        \"langchain\",\n",
            "        \"schema\",\n",
            "        \"messages\",\n",
            "        \"ToolMessage\"\n",
            "      ],\n",
            "      \"kwargs\": {\n",
            "        \"content\": \"Current location in sf is 72 fahrenheit\",\n",
            "        \"tool_call_id\": \"call_ByENVAlPvpTBvqqrr0vTAfCv\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 17:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are very powerful assistant, but don't know current events\\nHuman: what is the weather is sf?\\nAI: \\nTool: Current location in sf is 72 fahrenheit\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 17:llm:ChatOpenAI] [825ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"The current weather in sf is 72 fahrenheit. \",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"The current weather in sf is 72 fahrenheit. \",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 15,\n",
            "      \"prompt_tokens\": 319,\n",
            "      \"total_tokens\": 334\n",
            "    },\n",
            "    \"model_name\": \"accounts/fireworks/models/fw-function-call-34b-v0\",\n",
            "    \"system_fingerprint\": null\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 18:parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 18:parser:OpenAIToolsAgentOutputParser] [2ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"schema\",\n",
            "    \"agent\",\n",
            "    \"AgentFinish\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"return_values\": {\n",
            "      \"output\": \"The current weather in sf is 72 fahrenheit. \"\n",
            "    },\n",
            "    \"log\": \"The current weather in sf is 72 fahrenheit. \"\n",
            "  }\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence] [841ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [871ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"The current weather in sf is 72 fahrenheit. \"\n",
            "}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'what is the weather is sf?',\n",
              " 'output': 'The current weather in sf is 72 fahrenheit. '}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regular LLM"
      ],
      "metadata": {
        "id": "cFDUS084-EF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import Fireworks\n",
        "llm = Fireworks(\n",
        "          fireworks_api_key=env['fireworks.ai']['apiKey'],\n",
        "          model=\"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
        "          model_kwargs={\"temperature\": 0, \"max_tokens\": 4096},\n",
        "      )"
      ],
      "metadata": {
        "id": "U39jfmwAEG0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5b4a54d-6eda-408a-d3c2-ab5a6937c138"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `Fireworks` was deprecated in LangChain 0.0.26 and will be removed in 0.2. An updated version of the class exists in the langchain-fireworks package and should be used instead. To use it run `pip install -U langchain-fireworks` and import as `from langchain_fireworks import Fireworks`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "REACT_PROMPT = \"\"\"\n",
        "Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "Thought:{agent_scratchpad}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "          input_variables=[\"tools\", \"tool_name\", \"input\", \"agent_scratchpad\"],\n",
        "          template=REACT_PROMPT,\n",
        "      )"
      ],
      "metadata": {
        "id": "Z1eKG3Rn-GUo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title We need our own parser to handle our prompt\n",
        "import re\n",
        "import json\n",
        "from typing import Union\n",
        "\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "\n",
        "from langchain.agents.agent import AgentOutputParser\n",
        "from langchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS\n",
        "\n",
        "FINAL_ANSWER_ACTION = \"Final Answer:\"\n",
        "MISSING_ACTION_AFTER_THOUGHT_ERROR_MESSAGE = (\n",
        "    \"Invalid Format: Missing 'Action:' after 'Thought:\"\n",
        ")\n",
        "MISSING_ACTION_INPUT_AFTER_ACTION_ERROR_MESSAGE = (\n",
        "    \"Invalid Format: Missing 'Action Input:' after 'Action:'\"\n",
        ")\n",
        "FINAL_ANSWER_AND_PARSABLE_ACTION_ERROR_MESSAGE = (\n",
        "    \"Parsing LLM output produced both a final answer and a parse-able action:\"\n",
        ")\n",
        "\n",
        "\n",
        "class ReActSingleActionInputJsonOutputParser(AgentOutputParser):\n",
        "    \"\"\"Parses ReAct-style LLM calls that have a single tool input.\n",
        "\n",
        "    Expects output to be in one of two formats.\n",
        "\n",
        "    If the output signals that an action should be taken,\n",
        "    should be in the below format. This will result in an AgentAction\n",
        "    being returned.\n",
        "\n",
        "    ```\n",
        "    Thought: agent thought here\n",
        "    Action: search\n",
        "    Action Input: { location: 'San francisco' }\n",
        "    ```\n",
        "\n",
        "    If the output signals that a final answer should be given,\n",
        "    should be in the below format. This will result in an AgentFinish\n",
        "    being returned.\n",
        "\n",
        "    ```\n",
        "    Thought: agent thought here\n",
        "    Final Answer: The temperature is 100 degrees\n",
        "    ```\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def get_format_instructions(self) -> str:\n",
        "        return FORMAT_INSTRUCTIONS\n",
        "\n",
        "    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n",
        "        includes_answer = FINAL_ANSWER_ACTION in text\n",
        "        regex = (\n",
        "            r\"Action\\s*\\d*\\s*:[\\s]*(.*?)[\\s]*Action\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
        "        )\n",
        "        action_match = re.search(regex, text, re.DOTALL)\n",
        "        if action_match:\n",
        "            if includes_answer:\n",
        "                raise OutputParserException(\n",
        "                    f\"{FINAL_ANSWER_AND_PARSABLE_ACTION_ERROR_MESSAGE}: {text}\"\n",
        "                )\n",
        "            action = action_match.group(1).strip()\n",
        "            action_input = action_match.group(2)\n",
        "            tool_input = action_input.strip(\" \")\n",
        "            tool_input = tool_input.strip('\"')\n",
        "            # Convert string to dictionary\n",
        "            tool_input = json.loads(tool_input.replace(\"'\", \"\\\"\"))\n",
        "\n",
        "            print(\"printing tool input\", type(tool_input))\n",
        "\n",
        "            return AgentAction(action, tool_input, text)\n",
        "\n",
        "        elif includes_answer:\n",
        "            return AgentFinish(\n",
        "                {\"output\": text.split(FINAL_ANSWER_ACTION)[-1].strip()}, text\n",
        "            )\n",
        "\n",
        "        if not re.search(r\"Action\\s*\\d*\\s*:[\\s]*(.*?)\", text, re.DOTALL):\n",
        "            raise OutputParserException(\n",
        "                f\"Could not parse LLM output: `{text}`\",\n",
        "                observation=MISSING_ACTION_AFTER_THOUGHT_ERROR_MESSAGE,\n",
        "                llm_output=text,\n",
        "                send_to_llm=True,\n",
        "            )\n",
        "        elif not re.search(\n",
        "            r\"[\\s]*Action\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\", text, re.DOTALL\n",
        "        ):\n",
        "            raise OutputParserException(\n",
        "                f\"Could not parse LLM output: `{text}`\",\n",
        "                observation=MISSING_ACTION_INPUT_AFTER_ACTION_ERROR_MESSAGE,\n",
        "                llm_output=text,\n",
        "                send_to_llm=True,\n",
        "            )\n",
        "        else:\n",
        "            raise OutputParserException(f\"Could not parse LLM output: `{text}`\")\n",
        "\n",
        "    @property\n",
        "    def _type(self) -> str:\n",
        "        return \"react-single-action-input-json\""
      ],
      "metadata": {
        "id": "iJxuj4bFBmkE"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain.tools.render import render_text_description_and_args\n",
        "from langchain.agents.output_parsers import ReActSingleInputOutputParser\n",
        "\n",
        "tools = [GetCurrentWeather(), GetFlightOffers()]\n",
        "\n",
        "# We don't use `create_tool_calling_agent` because Mistral doesn't support tool calling (unless we use fire function)\n",
        "# Instead we use regular `create_react_agent`\n",
        "react_agent = create_react_agent(\n",
        "    llm=llm,\n",
        "    tools=tools,\n",
        "    prompt=prompt,\n",
        "    output_parser=ReActSingleActionInputJsonOutputParser(),\n",
        "    tools_renderer=render_text_description_and_args\n",
        ")\n",
        "\n",
        "# executes the logical steps we created\n",
        "agent_executor = AgentExecutor(\n",
        "  agent=react_agent,\n",
        "  tools=tools,\n",
        "  verbose=True,\n",
        "  handle_parsing_errors=True,\n",
        "  max_iterations = 5 # useful when agent is stuck in a loop\n",
        ")\n",
        "\n",
        "agent_executor.invoke({\"input\": \"What's the cheapest flight to madrid?\"})"
      ],
      "metadata": {
        "id": "Adz2Zoai-Tqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5994e0cd-8568-44b1-cd91-3ec32050a4b3"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"What's the cheapest flight to madrid?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"agent_scratchpad\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] [9ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"input\": \"What's the cheapest flight to madrid?\",\n",
            "  \"intermediate_steps\": [],\n",
            "  \"agent_scratchpad\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:PromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"What's the cheapest flight to madrid?\",\n",
            "  \"intermediate_steps\": [],\n",
            "  \"agent_scratchpad\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:Fireworks] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Answer the following questions as best you can. You have access to the following tools:\\n\\nget_current_weather: Get the current weather in a given location, args: {'location': {'description': 'The city and state, e.g. San Francisco, CA', 'title': 'Location', 'type': 'string'}, 'unit': {'anyOf': [{'enum': ['celcius', 'fahrenheit'], 'type': 'string'}, {'type': 'null'}], 'description': 'The temperature unit value', 'title': 'Unit'}}\\nget_flights_offer: Search for flight information, args: {'originLocationCode': {'description': 'City/airport IATA code from which the traveler will depart, e.g., BOS for Boston (Required)', 'title': 'Originlocationcode', 'type': 'string'}, 'destinationLocationCode': {'description': 'City/airport IATA code to which the traveler is going, e.g., PAR for Paris (Required)', 'title': 'Destinationlocationcode', 'type': 'string'}, 'departureDate': {'description': 'The date on which the traveler will depart from the origin to go to the destination, in YYYY-MM-DD format (Required)', 'title': 'Departuredate', 'type': 'string'}, 'returnDate': {'description': 'The date on which the traveler will depart from the destination to return to the origin, in YYYY-MM-DD format', 'title': 'Returndate', 'type': 'string'}, 'adults': {'description': 'The number of adult travelers (age 12 or older on the date of departure) (Required)', 'title': 'Adults', 'type': 'integer'}}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [get_current_weather, get_flights_offer]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: What's the cheapest flight to madrid?\\nThought:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:Fireworks] [1.11s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"To answer this question, I need to find the cheapest flight to Madrid. I can use the get_flights_offer action to search for flights. I'll set the destinationLocationCode to 'MAD' for Madrid, Spain. I'll set the unit to 'USD' for US Dollars. I'll start by setting the departureDate to a date one week from today. I'll set the returnDate to two weeks from today. I'll set the adults to 1.\\nAction: get_flights_offer\\nAction Input: {\\n  \\\"originLocationCode\\\": \\\"JFK\\\",\\n  \\\"destinationLocationCode\\\": \\\"MAD\\\",\\n  \\\"departureDate\\\": \\\"{{next_week}}\\\",\\n  \\\"returnDate\\\": \\\"{{two_weeks}}\\\",\\n  \\\"adults\\\": 1\\n}\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"Generation\"\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:ReActSingleActionInputJsonOutputParser] Entering Parser run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"To answer this question, I need to find the cheapest flight to Madrid. I can use the get_flights_offer action to search for flights. I'll set the destinationLocationCode to 'MAD' for Madrid, Spain. I'll set the unit to 'USD' for US Dollars. I'll start by setting the departureDate to a date one week from today. I'll set the returnDate to two weeks from today. I'll set the adults to 1.\\nAction: get_flights_offer\\nAction Input: {\\n  \\\"originLocationCode\\\": \\\"JFK\\\",\\n  \\\"destinationLocationCode\\\": \\\"MAD\\\",\\n  \\\"departureDate\\\": \\\"{{next_week}}\\\",\\n  \\\"returnDate\\\": \\\"{{two_weeks}}\\\",\\n  \\\"adults\\\": 1\\n}\"\n",
            "}\n",
            "printing tool input <class 'dict'>\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:ReActSingleActionInputJsonOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] [1.13s] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:get_flights_offer] Entering Tool run with input:\n",
            "\u001b[0m\"{'originLocationCode': 'JFK', 'destinationLocationCode': 'MAD', 'departureDate': '{{next_week}}', 'returnDate': '{{two_weeks}}', 'adults': 1}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:get_flights_offer] [0ms] Exiting Tool run with output:\n",
            "\u001b[0m\"The cheapest price from JFK to MAD given the dates {{next_week}} - {{two_weeks}} is 500EUR.\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad> > 13:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad> > 13:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"To answer this question, I need to find the cheapest flight to Madrid. I can use the get_flights_offer action to search for flights. I'll set the destinationLocationCode to 'MAD' for Madrid, Spain. I'll set the unit to 'USD' for US Dollars. I'll start by setting the departureDate to a date one week from today. I'll set the returnDate to two weeks from today. I'll set the adults to 1.\\nAction: get_flights_offer\\nAction Input: {\\n  \\\"originLocationCode\\\": \\\"JFK\\\",\\n  \\\"destinationLocationCode\\\": \\\"MAD\\\",\\n  \\\"departureDate\\\": \\\"{{next_week}}\\\",\\n  \\\"returnDate\\\": \\\"{{two_weeks}}\\\",\\n  \\\"adults\\\": 1\\n}\\nObservation: The cheapest price from JFK to MAD given the dates {{next_week}} - {{two_weeks}} is 500EUR.\\nThought: \"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad>] [6ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"agent_scratchpad\": \"To answer this question, I need to find the cheapest flight to Madrid. I can use the get_flights_offer action to search for flights. I'll set the destinationLocationCode to 'MAD' for Madrid, Spain. I'll set the unit to 'USD' for US Dollars. I'll start by setting the departureDate to a date one week from today. I'll set the returnDate to two weeks from today. I'll set the adults to 1.\\nAction: get_flights_offer\\nAction Input: {\\n  \\\"originLocationCode\\\": \\\"JFK\\\",\\n  \\\"destinationLocationCode\\\": \\\"MAD\\\",\\n  \\\"departureDate\\\": \\\"{{next_week}}\\\",\\n  \\\"returnDate\\\": \\\"{{two_weeks}}\\\",\\n  \\\"adults\\\": 1\\n}\\nObservation: The cheapest price from JFK to MAD given the dates {{next_week}} - {{two_weeks}} is 500EUR.\\nThought: \"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad>] [11ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 14:prompt:PromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 14:prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 15:llm:Fireworks] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Answer the following questions as best you can. You have access to the following tools:\\n\\nget_current_weather: Get the current weather in a given location, args: {'location': {'description': 'The city and state, e.g. San Francisco, CA', 'title': 'Location', 'type': 'string'}, 'unit': {'anyOf': [{'enum': ['celcius', 'fahrenheit'], 'type': 'string'}, {'type': 'null'}], 'description': 'The temperature unit value', 'title': 'Unit'}}\\nget_flights_offer: Search for flight information, args: {'originLocationCode': {'description': 'City/airport IATA code from which the traveler will depart, e.g., BOS for Boston (Required)', 'title': 'Originlocationcode', 'type': 'string'}, 'destinationLocationCode': {'description': 'City/airport IATA code to which the traveler is going, e.g., PAR for Paris (Required)', 'title': 'Destinationlocationcode', 'type': 'string'}, 'departureDate': {'description': 'The date on which the traveler will depart from the origin to go to the destination, in YYYY-MM-DD format (Required)', 'title': 'Departuredate', 'type': 'string'}, 'returnDate': {'description': 'The date on which the traveler will depart from the destination to return to the origin, in YYYY-MM-DD format', 'title': 'Returndate', 'type': 'string'}, 'adults': {'description': 'The number of adult travelers (age 12 or older on the date of departure) (Required)', 'title': 'Adults', 'type': 'integer'}}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [get_current_weather, get_flights_offer]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: What's the cheapest flight to madrid?\\nThought:To answer this question, I need to find the cheapest flight to Madrid. I can use the get_flights_offer action to search for flights. I'll set the destinationLocationCode to 'MAD' for Madrid, Spain. I'll set the unit to 'USD' for US Dollars. I'll start by setting the departureDate to a date one week from today. I'll set the returnDate to two weeks from today. I'll set the adults to 1.\\nAction: get_flights_offer\\nAction Input: {\\n  \\\"originLocationCode\\\": \\\"JFK\\\",\\n  \\\"destinationLocationCode\\\": \\\"MAD\\\",\\n  \\\"departureDate\\\": \\\"{{next_week}}\\\",\\n  \\\"returnDate\\\": \\\"{{two_weeks}}\\\",\\n  \\\"adults\\\": 1\\n}\\nObservation: The cheapest price from JFK to MAD given the dates {{next_week}} - {{two_weeks}} is 500EUR.\\nThought:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 15:llm:Fireworks] [590ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"I now know the final answer\\nFinal Answer: The cheapest flight to Madrid I found is 500EUR.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"Generation\"\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 16:parser:ReActSingleActionInputJsonOutputParser] Entering Parser run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"I now know the final answer\\nFinal Answer: The cheapest flight to Madrid I found is 500EUR.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 16:parser:ReActSingleActionInputJsonOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence] [611ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [1.76s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"The cheapest flight to Madrid I found is 500EUR.\"\n",
            "}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"What's the cheapest flight to madrid?\",\n",
              " 'output': 'The cheapest flight to Madrid I found is 500EUR.'}"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    }
  ]
}